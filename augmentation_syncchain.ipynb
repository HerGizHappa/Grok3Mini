{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9BCNOvT1auc"
      },
      "source": [
        "# Setup & Bibliotheken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "nhCh6T2Crh3u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "b75658a2-a2fd-4556-d388-3772b303ae52"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# Schritt 1: Deinstalliere alle problematischen Pakete\\n!pip uninstall tensorflow tensorflow-text tf-keras tensorflow-decision-forests tensorflow-probability -y\\n\\n# Schritt 2: Installiere kompatible Versionen\\n!pip install tensorflow==2.19.0 tensorflow-probability==0.25.0 tensorflow-text==2.19.0 tf-keras==2.19.0\\n\\n!pip install -q sentence-transformers transformers accelerate torch pandas tqdm\\n\\n# Schritt 3: Unterdrücke Warnungen (für parakeet und CUDA)\\nimport os\\nos.environ[\\'TF_CPP_MIN_LOG_LEVEL\\'] = \\'2\\'  # Unterdrückt TensorFlow-Warnungen\\n\\n# Schritt 4: Teste den Import\\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\\nprint(\"Import erfolgreich!\")\\n\\n# Schritt 5: Teste tensorflow_probability\\nimport tensorflow_probability as tfp\\nprint(f\"TensorFlow Probability Version: {tfp.__version__}\")\\n!pip install transformers torch pandas tqdm -q'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "'''# Schritt 1: Deinstalliere alle problematischen Pakete\n",
        "!pip uninstall tensorflow tensorflow-text tf-keras tensorflow-decision-forests tensorflow-probability -y\n",
        "\n",
        "# Schritt 2: Installiere kompatible Versionen\n",
        "!pip install tensorflow==2.19.0 tensorflow-probability==0.25.0 tensorflow-text==2.19.0 tf-keras==2.19.0\n",
        "\n",
        "!pip install -q sentence-transformers transformers accelerate torch pandas tqdm\n",
        "\n",
        "# Schritt 3: Unterdrücke Warnungen (für parakeet und CUDA)\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Unterdrückt TensorFlow-Warnungen\n",
        "\n",
        "# Schritt 4: Teste den Import\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "print(\"Import erfolgreich!\")\n",
        "\n",
        "# Schritt 5: Teste tensorflow_probability\n",
        "import tensorflow_probability as tfp\n",
        "print(f\"TensorFlow Probability Version: {tfp.__version__}\")\n",
        "!pip install transformers torch pandas tqdm -q'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VhqmpRX0F-WE"
      },
      "outputs": [],
      "source": [
        "\n",
        "import platform #infos aus dem System verarbeiten können (Windows)\n",
        "import os #für Dateihändelung\n",
        "import pandas as pd #für Datenanalyse (Bereinigung von Daten)\n",
        "import random\n",
        "from tqdm import tqdm #um ausgeben zu können, wie weit die Prozesse laufen (für Prozess Balken)\n",
        "import tensorflow_probability as tfp # Wahrscheinlichekti von Ergebnissen analysieren & bewerten\n",
        "import torch # soll dabei helfen, schnellere Berechnungen zu machen (GPU)\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM #aus hugging face bibliothek, um Texte in Tokens umzuwandeln, Textsequenzen als Input und andere Textsequenzen ausgeben (Output)\n",
        "#Aufgabe: Übersetzen, Zusammenfassen, Generieren\n",
        "from sentence_transformers import SentenceTransformer, util #sentenceTranformer, damit werden Modelle geladen, die Texte in ganze Vektoren umwandeln\n",
        "#ür Sätze/Texte erzeugen → Ähnlichkeitsvergleiche\n",
        "from google.colab import files, drive #Interaktion mit lokalen Dateien in Google Colab Umgebung\n",
        "from datetime import datetime# Manipulation von Zeitangaben\n",
        "import shutil #Operationen mit Dateien und mit dem Sammeln von Dateien\n",
        "import re #Operationen für reguläre Ausdrücke (regex)\n",
        "import json\n",
        "import math\n",
        "#from google.colab import drive\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NqgyTXTb2AqA"
      },
      "outputs": [],
      "source": [
        "def smartEncoding():\n",
        "  plt = platform.system\n",
        "  if plt == \"Windows\":\n",
        "    return \"utf-8-sig\"\n",
        "  else:\n",
        "    return \"utf-8\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6sxMd7fsqOR"
      },
      "source": [
        "# Gewählte xlsl Datei in csv Datei umwandeln und umbenennen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "VaFrz040hSDp",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "\n",
        "read_file = pd.DataFrame(pd.read_excel('/content/drive/My Drive/Google_Rezensionen_qualitätsgesichert_2023_12_19 (1).xlsx'))\n",
        "read_file.to_csv(\"Google_Rezensionen_qualitätsgesichert_2023_12_19 (1).csv\", index = False, header = True, encoding=smartEncoding())\n",
        "df = pd.DataFrame(pd.read_csv(\"Google_Rezensionen_qualitätsgesichert_2023_12_19 (1).csv\"))\n",
        "#print(df.head)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "q4FshCWEs1-J",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "#wähle relevante Spalten\n",
        "gewaehlte_spalten = df[[\"Erfahrungsbericht des Nutzers\" , \"Zufallszahl\"]]\n",
        "\n",
        "#speichere sie in neue csv datei\n",
        "gewaehlte_spalten.to_csv(\"/content/drive/My Drive/erfahrungen_gefiltert.csv\", index = False)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nfd5RwKdjNQv"
      },
      "source": [
        "# Datenbereinigung"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "etZLmS_XhRox",
        "outputId": "0cf77e72-16ff-46b8-bef8-672fe51bc91c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FINAL: 6453 Reihen\n",
            "100 Zufallsberichte!\n"
          ]
        }
      ],
      "source": [
        "erfahrungen_gefiltert = pd.read_csv(\"/content/drive/My Drive/erfahrungen_gefiltert.csv\")\n",
        "# dropna() entfernt NaN-Reihen aus anderen Spalten\n",
        "erfahrungen_gefiltert.dropna(subset=['Erfahrungsbericht des Nutzers'], inplace=True)\n",
        "# leere strings entfernen\n",
        "erfahrungen_gefiltert.drop_duplicates(inplace=True)\n",
        "#speichern\n",
        "erfahrungen_gefiltert.to_csv(\"/content/drive/My Drive/erfahrungen_clean.csv\", index=False)# Entfernung von Duplikaten wurde beim df selbst vollzogen anstatt als Kopie\n",
        "print(f\"FINAL: {len(erfahrungen_gefiltert)} Reihen\")\n",
        "\n",
        "\n",
        "#speichere sie in neue csv datei\n",
        "gewaehlte_spalten.to_csv(\"/content/drive/My Drive/erfahrungen_clean.csv\", index = False)\n",
        "\n",
        "\n",
        "#zufällig n = 100 Berichte für erfahrungen_final.csv auswählen\n",
        "erfahrungen_clean = pd.read_csv(\"/content/drive/My Drive/erfahrungen_clean.csv\")\n",
        "# dropna() entfernt NaN-Reihen aus anderen Spalten\n",
        "erfahrungen_clean.dropna(subset=['Erfahrungsbericht des Nutzers'], inplace=True)\n",
        "# leere strings entfernen\n",
        "erfahrungen_clean.drop_duplicates(inplace=True)\n",
        "erfahrungen_clean.to_csv(\"/content/drive/My Drive/erfahrungen_clean.csv\", index = False)\n",
        "\n",
        "# INDEX-Nummern zufällig wählen\n",
        "zufalls_index = random.sample(range(len(erfahrungen_clean)), k=100)\n",
        "zufall_100 = erfahrungen_clean.iloc[zufalls_index]\n",
        "\n",
        "\n",
        "\n",
        "#speichern (NUR 100!)\n",
        "zufall_100.to_csv(\"/content/drive/My Drive/zufall_100_berichte.csv\", index=False)\n",
        "\n",
        "print(f\"{len(zufall_100)} Zufallsberichte!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPzrsAJjFsW2"
      },
      "source": [
        "# **Datenaugmentation und Syn-Chain-Methode**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDX0N5V-IhnY"
      },
      "source": [
        "## Datenaugmentation mit Trainingsdaten (ca. 11.900 Rezensionen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8p0Z4ygud_8_"
      },
      "source": [
        "## Paraphrasieren"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkXOEJrCaMv2",
        "outputId": "6b1a9911-e352-4904-f0f7-9333e9ec31de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Ordner & Bibliotheken geladen!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Google Drive mounten/ Ordner in Google Colab Umbegung erstellen lassen (einmalige Ausführung nötig)\n",
        "drive.mount('/content/drive')\n",
        "SAVE_PATH = '/content/drive/MyDrive/ABSA_Paraphrase/' #Unterordner \"ABSA_Paraphrase\" in Google Colab Umgebung erstellen\n",
        "os.makedirs(SAVE_PATH, exist_ok=True) #Methode, wobei ein Projektverzeichnis (Pfad für Paraphrase mit inbegriffen) festgelegt wird\n",
        "\n",
        "print(\"Ordner & Bibliotheken geladen!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Beste Lösung bislang"
      ],
      "metadata": {
        "id": "fttVfq7ddRec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def smartEncoding():\n",
        "  plt = platform.system\n",
        "  if plt == \"Windows\":\n",
        "    return \"utf-8-sig\"\n",
        "  else:\n",
        "    return \"utf-8\"\n",
        "\n",
        "# Paraphrasierung\n",
        "\n",
        "# Erstellung eines \"Synonym-Dictionarys\", zuerste mit Schlüsselwert wie z.B. \"schmutzig\" & danach Wertpaaren, Duplikate nicht erlaubt\n",
        "SYNONYMS = {\n",
        "    \"schmutzig\": [\"dreckig\", \"unhygienisch\", \"unrein\" , \"unsauber\", \"verschmutzt\", \"versifft\", \"gammelig\", \"schmuddelig\"],\n",
        "    \"hygienisch\": [\"sauber\", \"rein\", \"keimfrei\", \"gesäubert\", \"picobello\", \"blitzeblank\"],\n",
        "    \"arbeite\": [\"bin tätig\", \"beschäftigt\", \"bin angestellt\"],\n",
        "    \"seit\": [\"seit etwa\", \"schon seit\", \"seit circa\"],\n",
        "    \"im\": [\"in\", \"bei\"],\n",
        "    \"und\": [\"sowie\", \"–\", \"&\"],\n",
        "    \"Mutter\": [\"familienangehörige\"],\n",
        "    \"Vater\": [\"familienangehöriger\"],\n",
        "    \"Großvater\": [\"opa\"],\n",
        "    \"Großmutter\": [\"oma\"],\n",
        "    \"waren\": [\"lebten\", \"wohnten\"],\n",
        "    \"dort\": [\"dort\", \"im Heim\", \"in der Einrichung\"],\n",
        "    \"ist\": [\"bleibt\"],\n",
        "    \"sehr\": [\"wirklich\", \"besonders\"],\n",
        "    \"kollegial\": [\"freundschaftlich\", \"kameradschaftlich\", \"wie ein guter Kollege\"],\n",
        "    \"Betreuung\": [\"pflege\", \"fürsorge\", \"hilfe\", \"obhut\", \"unterstützung\"],\n",
        "    \"Bewohner\": [\"senioren\", \"pflegebedürftige\"],\n",
        "    \"Essen\": [ \"Speisen\", \"Nahrung\"],\n",
        "    \"Fest\": [\"feier\", \"party\" \"fete\"],\n",
        "    \"beliebt\": [\"geschätzt\", \"begehrt\", \"wird gemocht\"],\n",
        "    \"schlecht\": [\"mies\", \"mieserabel\", \"schrecklich\" \"mangelhaft\", \"unkorrekt\", \"daneben\"],\n",
        "    \"warum\": [\"weshalb\", \"wieso\"],\n",
        "    \"toll\": [\"super\", \"top\", \"einwandfrei\", \"hammer\"],\n",
        "    \"tolle\": [\"einwandfreie\", \"hammermäßige\"],\n",
        "    \"sauber\": [\"ordentlich\", \"gepflegt\"],\n",
        "    \"frische\": [\"angenehme\"],\n",
        "    \"lecker\": [\"köstlich\", \"schmackhaft\", \"gut\"],\n",
        "    \"okay\": [\"in Ordnung\", \"befriedigend\"],\n",
        "    \"traurig\": [\"schade\", \"deprimierend\"],\n",
        "    \"Pflegeheim\": [\"stationäre Pflegeheim\"],\n",
        "    \"Haus\": [\"Heim\"],\n",
        "    \"Einrichtung\": [\"Institution\"],\n",
        "    \"freundlich\": [\"höflich\", \"zuvorkommend\"],\n",
        "    \"unhöflich\": [\"unsensibel\", \"nicht nett\", \"unfreundlich\"],\n",
        "    \"kompetent\": [\"fähig\", \"professionell\", \"tüchtig\", \"effektiv\"],\n",
        "    \"nett\": [\"herzlich\", \"symphatisch\", \"angenehm\"],\n",
        "    \"nette\": [\"angenehme\", \"symphatische\", \"gute\"],\n",
        "    \"nettes\": [\"angenehmes\", \"symphatisches\", \"herzliches\"],\n",
        "    \"Oma\": [\"großmutter\", \"Omi\"],\n",
        "    \"Opa\": [\"Großvater\", \"Opi\"],\n",
        "    \"Ahnung\": [\"kenntniss\", \"Wissen\" ],\n",
        "    \"Vorher\": [\"davor\", \"damals\"],\n",
        "    \"Mitarbeiter\": [\"beschäftigten\", \"pflegenden\", \"angestellten\"],\n",
        "    \"motiviert\": [\"engagiert\", \"eifrig\", \"arbeitsfreudig\"],\n",
        "    \"Arbeitsklima\": [\"Klima bei der Arbeit\"],\n",
        "    \"Katastrophe\": [\"Zumutung\"]\n",
        "\n",
        "}# kann noch erweitert werden!\n",
        "\n",
        "\n",
        "def synonym_replace(text): #nimmt Text an einer bestimmten Stelle aus Spalte \"Erfahrungsberichts des Nutzers\" aus erfahrungen_clean.csv entgegen\n",
        "    words = text.split() # Variable, in welches einzelne Wörter in text als Tokens in eine Liste gepackt werden [\"wort1\", \"wort2\",...]\n",
        "    new_words = [] #neue liste erstellen\n",
        "    for w in words: #schleife\n",
        "        lower = w.lower().rstrip('.,!?') # buchstaben in kleine Buchstaben schreiben, Satzzeichen vom Ende des Strings entfernen\n",
        "        if lower in SYNONYMS and random.random() < 0.5: #wenn Wort in dict Synonym vorhanden ist\n",
        "        #: nicht jedes einzelne Wort ersetzen; Nur in 50% der Fälle ein Synonym ersetzen\n",
        "            repl = random.choice(SYNONYMS[lower]) #nicht jedes einzelne Wort ersetzen; Nur in 50% der Fälle ein Synonym ersetzen\n",
        "            if w[0].isupper(): repl = repl.capitalize()#wenn der erste Buchstabe von w groß ist (True/False):\n",
        "              #Schreibe den ersten Buchstaben des Synonym auch groß!\n",
        "            new_words.append(repl + w[len(lower):]) #füge in leere Liste das Synonym, mit ersten Buchstaben und restlichen kleingeschriebenen\n",
        "            #print(w[len(lower):])\n",
        "        else: #wenn anfangsbuchstabe nicht groß ist\n",
        "            new_words.append(w) #füge zur Liste das ganze Wort hinzu\n",
        "    return ' '.join(new_words) #Rückgabe der Elemente von Liste & mache diesen zu einem Satz mit Leerzeichen als Seperator\n",
        "\n",
        "#funktion für Parahrase\n",
        "def hybrid_paraphrase(text, n=3):\n",
        "    original = str(text).strip()\n",
        "    if len(original) < 20:\n",
        "        return [original] * n\n",
        "\n",
        "    results = set()\n",
        "    max_attempts = n * 5  # max. 15 Versuche\n",
        "\n",
        "    for _ in range(max_attempts):\n",
        "        if len(results) >= n:#wenn der Satz länger als drei Wörter lang ist, stop diese Schleife!\n",
        "            break\n",
        "\n",
        "        step1 = synonym_replace(original)#nimm Originaltext aus Zeile von \"Erfahrungsbericht des Nutzers\" als Parameter\n",
        "        if len(step1.split()) > 10 and random.random() < 0.3:\n",
        "            sentences = re.split(r'(?<=[.!?])\\s+', step1)\n",
        "           # print(sentences) Beispiel: ['Ein sehr schönes Haus mit altem Charme, ländlich gelegen.', '...]\n",
        "            if len(sentences) > 1:\n",
        "                random.shuffle(sentences)# um die Satzstruktur zu verändern, wenn der Satz lang genug ist\n",
        "                step1 = ' '.join(sentences)# geshuffelte sentences zum ganzen Satz machen\n",
        "        results.add(step1)#ist noch ein set z.B. {'Die Vergabe von einem od 2 Sternen kann....'}\n",
        "\n",
        "    # garantierte Ausgabe,damit Prgramm an dieser schleife nicht hängen bleibt\n",
        "    result_list = list(results)\n",
        "    while len(result_list) < n:\n",
        "        result_list.append(original)\n",
        "\n",
        "    return result_list[:n]\n",
        "\n",
        "# erfahrungen_clean.csv laden, falls noch nicht vorhanden\n",
        "try:\n",
        "    df\n",
        "except NameError:\n",
        "    df = pd.read_csv(\"/content/drive/MyDrive/erfahrungen_clean.csv\") # lieber direkten Pfad aufschreiben\n",
        "    df = df.dropna(subset=['Erfahrungsbericht des Nutzers']).reset_index(drop=True)\n",
        "    print(f\"{len(df)} Rezensionen geladen!\")\n",
        "\n",
        "# Test mit 10 Rezensionen aus erfahrungen_clean.csv\n",
        "test_indices = random.sample(range(len(df)), 10)\n",
        "print(f\"\\n10-TEST: HYBRID \\n\")\n",
        "print(\"=\"*90)\n",
        "\n",
        "for i, idx in enumerate(test_indices, 1):\n",
        "    text = str(df.iloc[idx]['Erfahrungsbericht des Nutzers'])\n",
        "    print(f\"\\n{i}. ORIGINAL (Index {idx}):\")\n",
        "    print(text[:200] + (\"...\" if len(text) > 200 else \"\"))\n",
        "    print(\"\\n   PARAPHRASEN:\")\n",
        "    paras = hybrid_paraphrase(text, 3)\n",
        "    for j, p in enumerate(paras, 1):\n",
        "        print(f\"   {j}: {p[:200]}{'...' if len(p) > 200 else ''}\")\n",
        "    print(\"-\" * 90)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bf8f8ee-91e9-4604-a306-56536bac91c1",
        "id": "J03xVNBOdTXH",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6453 Rezensionen geladen!\n",
            "\n",
            "10-TEST: HYBRID \n",
            "\n",
            "==========================================================================================\n",
            "\n",
            "1. ORIGINAL (Index 2433):\n",
            "Eine tolle Einrichtung mit liebevoller Betreuung und wunderbarem Garten. Dazu gibt es nebenan die Möglichkeit des Betreuten Wohnens. Gutes Seniorenheim!\n",
            "\n",
            "   PARAPHRASEN:\n",
            "   1: Eine hammermäßige Einrichtung mit liebevoller Betreuung & wunderbarem Garten. Dazu gibt es nebenan die Möglichkeit des Betreuten Wohnens. Gutes Seniorenheim!\n",
            "   2: Eine hammermäßige Einrichtung mit liebevoller Betreuung – wunderbarem Garten. Dazu gibt es nebenan die Möglichkeit des Betreuten Wohnens. Gutes Seniorenheim!\n",
            "   3: Gutes Seniorenheim! Dazu gibt es nebenan die Möglichkeit des Betreuten Wohnens. Eine hammermäßige Einrichtung mit liebevoller Betreuung und wunderbarem Garten.\n",
            "------------------------------------------------------------------------------------------\n",
            "\n",
            "2. ORIGINAL (Index 5739):\n",
            "Sehr schöne Einrichtung! Nettes Pflegepersonal! Tolle Einrichtungsleitung !\n",
            "\n",
            "   PARAPHRASEN:\n",
            "   1: Sehr schöne Einrichtung! Angenehmes Pflegepersonal! Einwandfreie Einrichtungsleitung !\n",
            "   2: Wirklich schöne Einrichtung! Herzliches Pflegepersonal! Tolle Einrichtungsleitung !\n",
            "   3: Sehr schöne Einrichtung! Nettes Pflegepersonal! Tolle Einrichtungsleitung !\n",
            "------------------------------------------------------------------------------------------\n",
            "\n",
            "3. ORIGINAL (Index 190):\n",
            "Führungsebene ganz ok, jedoch wenig Pflegepersonal und damit überlastet teilweise mit den einfachsten Dingen. Etwas ruppig im Umgang mit den Bewohnern. Sauerstoffflasche wird erst nach zwei Tagen aufg...\n",
            "\n",
            "   PARAPHRASEN:\n",
            "   1: Führungsebene ganz ok, jedoch wenig Pflegepersonal und damit überlastet teilweise mit den einfachsten Dingen. Etwas ruppig in Umgang mit den Bewohnern. Sauerstoffflasche wird erst nach zwei Tagen aufg...\n",
            "   2: Führungsebene ganz ok, jedoch wenig Pflegepersonal – damit überlastet teilweise mit den einfachsten Dingen. Etwas ruppig im Umgang mit den Bewohnern. Sauerstoffflasche wird erst nach zwei Tagen aufgef...\n",
            "   3: Führungsebene ganz ok, jedoch wenig Pflegepersonal und damit überlastet teilweise mit den einfachsten Dingen. Sauerstoffflasche wird erst nach zwei Tagen aufgefüllt.. Wer beim Essen nicht rechtzeitig ...\n",
            "------------------------------------------------------------------------------------------\n",
            "\n",
            "4. ORIGINAL (Index 4290):\n",
            "Nettes Personal\n",
            "\n",
            "   PARAPHRASEN:\n",
            "   1: Nettes Personal\n",
            "   2: Nettes Personal\n",
            "   3: Nettes Personal\n",
            "------------------------------------------------------------------------------------------\n",
            "\n",
            "5. ORIGINAL (Index 1085):\n",
            "Ich habe dort sehr gerne gearbeitet. Gruß Christian G .\n",
            "\n",
            "   PARAPHRASEN:\n",
            "   1: Ich habe in der Einrichung sehr gerne gearbeitet. Gruß Christian G .\n",
            "   2: Ich habe im Heim besonders gerne gearbeitet. Gruß Christian G .\n",
            "   3: Ich habe dort sehr gerne gearbeitet. Gruß Christian G .\n",
            "------------------------------------------------------------------------------------------\n",
            "\n",
            "6. ORIGINAL (Index 3148):\n",
            "Es hat mir wirklich Spaß gemacht, hier zu arbeiten\n",
            "\n",
            "   PARAPHRASEN:\n",
            "   1: Es hat mir wirklich Spaß gemacht, hier zu arbeiten\n",
            "   2: Es hat mir wirklich Spaß gemacht, hier zu arbeiten\n",
            "   3: Es hat mir wirklich Spaß gemacht, hier zu arbeiten\n",
            "------------------------------------------------------------------------------------------\n",
            "\n",
            "7. ORIGINAL (Index 6186):\n",
            "Bin immer sehr zufrieden dort...\n",
            "\n",
            "   PARAPHRASEN:\n",
            "   1: Bin immer sehr zufrieden dort...\n",
            "   2: Bin immer besonders zufrieden in der Einrichung...\n",
            "   3: Bin immer wirklich zufrieden in der Einrichung...\n",
            "------------------------------------------------------------------------------------------\n",
            "\n",
            "8. ORIGINAL (Index 3316):\n",
            "Etwas alt, aber eine besondere Lage Mitten in der Stadt!\n",
            "\n",
            "   PARAPHRASEN:\n",
            "   1: Etwas alt, aber eine besondere Lage Mitten in der Stadt!\n",
            "   2: Etwas alt, aber eine besondere Lage Mitten in der Stadt!\n",
            "   3: Etwas alt, aber eine besondere Lage Mitten in der Stadt!\n",
            "------------------------------------------------------------------------------------------\n",
            "\n",
            "9. ORIGINAL (Index 851):\n",
            "Ein Elternteil war 3 Wochen zur Kurzzeitpflege. Personal nett und freundlich. Aber viele Sachen weggekommen und nie mehr eine Antwort erhalten trotz mehrfachen Nachfragen.\n",
            "\n",
            "   PARAPHRASEN:\n",
            "   1: Ein Elternteil war 3 Wochen zur Kurzzeitpflege. Personal symphatisch sowie freundlich. Aber viele Sachen weggekommen und nie mehr eine Antwort erhalten trotz mehrfachen Nachfragen.\n",
            "   2: Aber viele Sachen weggekommen und nie mehr eine Antwort erhalten trotz mehrfachen Nachfragen. Ein Elternteil war 3 Wochen zur Kurzzeitpflege. Personal nett & freundlich.\n",
            "   3: Ein Elternteil war 3 Wochen zur Kurzzeitpflege. Personal nett – höflich. Aber viele Sachen weggekommen und nie mehr eine Antwort erhalten trotz mehrfachen Nachfragen.\n",
            "------------------------------------------------------------------------------------------\n",
            "\n",
            "10. ORIGINAL (Index 4618):\n",
            "Nett, Herzhaft\n",
            "\n",
            "   PARAPHRASEN:\n",
            "   1: Nett, Herzhaft\n",
            "   2: Nett, Herzhaft\n",
            "   3: Nett, Herzhaft\n",
            "------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyC2F4CTW-2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea522817-943c-4751-941d-9bb88db4d4a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "START: Paraphrasierung aller 6453 Rezensionen -> 19359 Samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Augmentiere: 100%|██████████| 6453/6453 [00:01<00:00, 3312.64text/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "FERTIG!\n",
            "→ 25812 Paraphrasen gespeichert\n",
            "→ Datei: /content/drive/MyDrive/ABSA_Paraphrase/augmented_erfahrungen.csv\n",
            "→ Robuster Datensatz für Grok 3 Mini bei der ABSA vorbereitet!\n"
          ]
        }
      ],
      "source": [
        "# finaler Batch: Alle Rezensionen aus \"efahrungen_clean.csv\" augmentieren\n",
        "print(f\"\\nSTART: Paraphrasierung aller {len(df)} Rezensionen -> {len(df)*3} Samples...\")\n",
        "aug_data = []\n",
        "\n",
        "for idx in tqdm(range(len(df)), desc=\"Augmentiere\", unit=\"text\"):\n",
        "    text = df.iloc[idx]['Erfahrungsbericht des Nutzers']\n",
        "    zufallszahl = int(df.iloc[idx]['Zufallszahl'])\n",
        "    aug_data.append({\n",
        "        'id': zufallszahl,\n",
        "        'original': text\n",
        "    })\n",
        "    variants = hybrid_paraphrase(text, 3)\n",
        "    for v_id, para in enumerate(variants, 1):\n",
        "      aug_data.append({\n",
        "          'variant_id': v_id,\n",
        "          'paraphrase': para\n",
        "      })\n",
        "\n",
        "# Speichern\n",
        "with open(\"data.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for group in aug_data:\n",
        "        f.write(json.dumps(group, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "aug_df = pd.DataFrame(aug_data)\n",
        "output_path = \"/content/drive/MyDrive/ABSA_Paraphrase/augmented_erfahrungen.csv\"\n",
        "aug_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"\\nFERTIG!\")\n",
        "print(f\"→ {len(aug_df)} Paraphrasen gespeichert\")\n",
        "print(f\"→ Datei: {output_path}\")\n",
        "print(f\"→ Robuster Datensatz für Grok 3 Mini bei der ABSA vorbereitet!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nan-Werte entfernen aus JSONL-Datei"
      ],
      "metadata": {
        "id": "In9SANSCO_lH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_file = \"/content/sample_data/data_training.jsonl\"\n",
        "output_file = \"cleaned_jsonl.jsonl\"\n",
        "\n",
        "def find_nan(obj):\n",
        "    if isinstance(obj, float):\n",
        "        return math.isnan(obj) or math.isinf(obj)\n",
        "    if isinstance(obj, dict):\n",
        "        return any(find_nan(v) for v in obj.values())\n",
        "    if isinstance(obj, list):\n",
        "        return any(find_nan(v) for v in obj)\n",
        "    return False\n",
        "\n",
        "with open(input_file, 'r', encoding='utf-8') as f, \\\n",
        "     open(output_file, 'w', encoding='utf-8') as fi:\n",
        "    for line in f:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "        try:\n",
        "            obj = json.loads(line)\n",
        "            if not find_nan(obj):\n",
        "                fi.write(json.dumps(obj, ensure_ascii=False) + '\\n')\n",
        "        except json.JSONDecodeError:\n",
        "            pass  # skip invalid lines\n",
        ""
      ],
      "metadata": {
        "id": "3LICNoAXWoNG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfZm6aOvPbPD"
      },
      "source": [
        "für Fine Tuning:\n",
        "Hugging Face: Fine-tune ein Grok-ähnliches Modell (z. B. \"xai-org/grok-1\" oder \"reedmayhew/Grok-3-gemma3-4B-distilled\" als Distillation von Grok 3). Das ist open-source und GitHub-freundlich.\n",
        "\n",
        "Code-Beispiel (Distillation von Grok 3 via API + Fine-Tuning auf Gemma-3 4B):\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0ywlg4TQWl2"
      },
      "source": [
        "Best Practices (aus Reddit, GitHub Blog, HF Docs):\n",
        "\n",
        "Lizenz: Füge eine LICENSE (z. B. Apache 2.0) hinzu, da Grok-Modelle proprietär sind – dein Fine-Tuning erbt das.\n",
        "Model Card: Erstelle eine (HF-Template: https://huggingface.co/docs/hub/model-cards) mit Details zu Daten (12.000 Rezensionen), Augmentation und Metriken.\n",
        "Datenschutz: Anonymisiere sensible Daten in der CSV (z. B. Namen entfernen), bevor du hochlädst – Pflegeberichte könnten personenbezogen sein (DSGVO-konform!).\n",
        "Versionskontrolle: Nutze GitHub Releases für große Dateien (z. B. Weights als Asset).\n",
        "Integration mit HF: Push zu Hugging Face Hub und verlinke im GitHub-Repo – HF ist GitHub-ähnlich und unterstützt Grok-Destillationen (z. B. \"reedmayhew/Grok-3-gemma3-4B-distilled\").\n",
        "\n",
        "\n",
        "\n",
        "3. Empfehlung für deine Bachelorarbeit\n",
        "\n",
        "Starte mit Option A/B: Prompt Engineering für schnelle Tests, dann Hugging Face für echtes Fine-Tuning (ca. 30–60 Min. in Colab mit GPU).\n",
        "GitHub-Repo als Portfolio: Lade Code, Skripte und Metriken hoch – das zeigt Reproduzierbarkeit. Vermeide rohe Weights (>100 MB) direkt; verlinke sie.\n",
        "Nächste Schritte: Hole dir einen xAI API-Key und HF-Token. Teste den Code in Colab.\n",
        "\n",
        "Falls du Hilfe beim Setup (z. B. API-Key, spezifischer Code-Fehler) brauchst oder mehr Details zu einer Option, lass es mich wissen!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b06VD1uYFlSq"
      },
      "outputs": [],
      "source": [
        "# um damit zu beginnen: https://arxiv.org/html/2507.09485"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1MecGjdw--8eqoUfF53VL3Vja6L0ROuUF",
      "authorship_tag": "ABX9TyO4J9qFbqFw8MWDtH8P2hTJ"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}