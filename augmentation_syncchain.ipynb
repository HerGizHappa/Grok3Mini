{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup & Bibliotheken"
      ],
      "metadata": {
        "id": "N9BCNOvT1auc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Schritt 1: Deinstalliere alle problematischen Pakete\n",
        "!pip uninstall tensorflow tensorflow-text tf-keras tensorflow-decision-forests tensorflow-probability -y\n",
        "\n",
        "# Schritt 2: Installiere kompatible Versionen\n",
        "!pip install tensorflow==2.19.0 tensorflow-probability==0.25.0 tensorflow-text==2.19.0 tf-keras==2.19.0\n",
        "\n",
        "!pip install -q sentence-transformers transformers accelerate torch pandas tqdm\n",
        "\n",
        "# Schritt 3: Unterdrücke Warnungen (für parakeet und CUDA)\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Unterdrückt TensorFlow-Warnungen\n",
        "\n",
        "# Schritt 4: Teste den Import\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "print(\"Import erfolgreich!\")\n",
        "\n",
        "# Schritt 5: Teste tensorflow_probability\n",
        "import tensorflow_probability as tfp\n",
        "print(f\"TensorFlow Probability Version: {tfp.__version__}\")\n",
        "!pip install transformers torch pandas tqdm -q"
      ],
      "metadata": {
        "id": "nhCh6T2Crh3u",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import platform\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import tensorflow_probability as tfp\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from google.colab import files, drive\n",
        "from datetime import datetime\n",
        "import time\n",
        "import shutil\n",
        "import re\n",
        "\n",
        "from google.colab import drive\n",
        "\n"
      ],
      "metadata": {
        "id": "VhqmpRX0F-WE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def smartEncoding():\n",
        "  plt = platform.system\n",
        "  if plt == \"Windows\":\n",
        "    return \"utf-8-sig\"\n",
        "  else:\n",
        "    return \"utf-8\""
      ],
      "metadata": {
        "id": "NqgyTXTb2AqA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6sxMd7fsqOR"
      },
      "source": [
        "# Gewählte xlsl Datei in csv Datei umwandeln und umbenennen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaFrz040hSDp",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "\n",
        "read_file = pd.DataFrame(pd.read_excel('/content/drive/My Drive/Google_Rezensionen_qualitätsgesichert_2023_12_19 (1).xlsx'))\n",
        "read_file.to_csv(\"Google_Rezensionen_qualitätsgesichert_2023_12_19 (1).csv\", index = False, header = True, encoding=smartEncoding())\n",
        "df = pd.DataFrame(pd.read_csv(\"Google_Rezensionen_qualitätsgesichert_2023_12_19 (1).csv\"))\n",
        "#print(df.head)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "q4FshCWEs1-J"
      },
      "outputs": [],
      "source": [
        "#wähle relevante Spalten\n",
        "gewaehlte_spalten = df[[\"Erfahrungsbericht des Nutzers\" , \"Zufallszahl\"]]\n",
        "\n",
        "#speichere sie in neue csv datei\n",
        "gewaehlte_spalten.to_csv(\"/content/drive/My Drive/erfahrungen_gefiltert.csv\", index = False)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nfd5RwKdjNQv"
      },
      "source": [
        "# Datenbereinigung"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "etZLmS_XhRox",
        "outputId": "202314f6-980c-4370-da37-4a14abae9c88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FINAL: 6453 Reihen\n",
            "100 Zufallsberichte!\n"
          ]
        }
      ],
      "source": [
        "erfahrungen_gefiltert = pd.read_csv(\"/content/drive/My Drive/erfahrungen_gefiltert.csv\")\n",
        "# dropna() entfernt NaN-Reihen aus anderen Spalten\n",
        "erfahrungen_gefiltert.dropna(subset=['Erfahrungsbericht des Nutzers'], inplace=True)\n",
        "# leere strings entfernen\n",
        "erfahrungen_gefiltert.drop_duplicates(inplace=True)\n",
        "#speichern\n",
        "erfahrungen_gefiltert.to_csv(\"/content/drive/My Drive/erfahrungen_clean.csv\", index=False)\n",
        "print(f\"FINAL: {len(erfahrungen_gefiltert)} Reihen\")\n",
        "\n",
        "\n",
        "#speichere sie in neue csv datei\n",
        "gewaehlte_spalten.to_csv(\"/content/drive/My Drive/erfahrungen_clean.csv\", index = False)\n",
        "\n",
        "\n",
        "#zufällig n = 100 Berichte für erfahrungen_final.csv auswählen\n",
        "erfahrungen_clean = pd.read_csv(\"/content/drive/My Drive/erfahrungen_clean.csv\")\n",
        "# dropna() entfernt NaN-Reihen aus anderen Spalten\n",
        "erfahrungen_clean.dropna(subset=['Erfahrungsbericht des Nutzers'], inplace=True)\n",
        "# leere strings entfernen\n",
        "erfahrungen_clean.drop_duplicates(inplace=True)\n",
        "erfahrungen_clean.to_csv(\"/content/drive/My Drive/erfahrungen_clean.csv\", index = False)\n",
        "\n",
        "# INDEX-Nummern zufällig wählen\n",
        "zufalls_index = random.sample(range(len(erfahrungen_clean)), k=100)\n",
        "zufall_100 = erfahrungen_clean.iloc[zufalls_index]\n",
        "\n",
        "\n",
        "\n",
        "#speichern (NUR 100!)\n",
        "zufall_100.to_csv(\"/content/drive/My Drive/zufall_100_berichte.csv\", index=False)\n",
        "\n",
        "print(f\"{len(zufall_100)} Zufallsberichte!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPzrsAJjFsW2"
      },
      "source": [
        "# **Datenaugmentation und Syn-Chain-Methode**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datenaugmentation mit Trainingsdaten (ca. 11.900 Rezensionen)"
      ],
      "metadata": {
        "id": "oDX0N5V-IhnY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paraphrasieren"
      ],
      "metadata": {
        "id": "8p0Z4ygud_8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Google Drive mounten\n",
        "drive.mount('/content/drive')\n",
        "SAVE_PATH = '/content/drive/MyDrive/ABSA_Paraphrase/'\n",
        "os.makedirs(SAVE_PATH, exist_ok=True)\n",
        "\n",
        "print(\"Ordner & Bibliotheken geladen!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkXOEJrCaMv2",
        "outputId": "d19cc511-8f02-449b-8119-72591ece579e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Ordner & Bibliotheken geladen!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vllt. ist das die beste Lösung?"
      ],
      "metadata": {
        "id": "sExwqN0MXBMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paraphrasierung\n",
        "\n",
        "SYNONYMS = {\n",
        "    \"schmutzig\": [\"dreckig\", \"unhygienisch\", \"unrein\" , \"unsauber\", \"verschmutzt\", \"versifft\", \"gammelig\", \"schmuddelig\"],\n",
        "    \"hygienisch\": [\"sauber\", \"rein\", \"keimfrei\", \"gesäubert\", \"picobello\", \"blitzeblank\"],\n",
        "    \"arbeite\": [\"bin tätig\", \"beschäftigt\", \"bin angestellt\"],\n",
        "    \"seit\": [\"seit etwa\", \"schon seit\"],\n",
        "    \"im\": [\"in\", \"bei\"],\n",
        "    \"und\": [\"sowie\", \"–\", \"&\"],\n",
        "    \"meine\": [\"meine beiden\"],\n",
        "    \"waren\": [\"lebten\", \"wohnten\"],\n",
        "    \"dort\": [\"dort\", \"im Heim\", \"in der Einrichung\"],\n",
        "    \"ist\": [\"bleibt\"],\n",
        "    \"sehr\": [\"wirklich\", \"besonders\"],\n",
        "    \"kollegial\": [\"freundschaftlich\", \"kameradschaftlich\", \"wie ein guter Kollege\"],\n",
        "    \"betreuung\": [\"Pflege\", \"Fürsorge\", \"Hilfe\", \"Obhut\", \"Unterstützung\"],\n",
        "    \"bewohner\": [\"Senioren\", \"Pflegebedürftige\"],\n",
        "    \"essen\": [\"Verpflegung\", \"Verköstigung\", \"Speisen\", \"Mahl\" , \"Nahrung\"],\n",
        "    \"fest\": [\"Feier\", \"Party\" \"Fete\"],\n",
        "    \"beliebt\": [\"geschätzt\", \"begehrt\", \"wird gemocht\"],\n",
        "    \"schlecht\": [\"mies\", \"mieserabel\", \"schrecklich\" \"mangelhaft\", \"unkorrekt\", \"daneben\"],\n",
        "    \"warum\": [\"weshalb\", \"wieso\"],\n",
        "    \"gut\": [\"angenehm\"],\n",
        "    \"top\": [\"super\", \"toll\", \"einwandfrei\", \"hammer\"],\n",
        "    \"sauber\": [\"ordentlich\", \"gepflegt\"],\n",
        "    \"lecker\": [\"köstlich\", \"schmackhaft\", \"gut\"]\n",
        "\n",
        "}# kann noch erweitert werden!\n",
        "\n",
        "def synonym_replace(text):\n",
        "    words = text.split()\n",
        "    new_words = []\n",
        "    for w in words:\n",
        "        lower = w.lower().rstrip('.,!?')\n",
        "        if lower in SYNONYMS and random.random() < 0.5:\n",
        "            repl = random.choice(SYNONYMS[lower])\n",
        "            if w[0].isupper(): repl = repl.capitalize()\n",
        "            new_words.append(repl + w[len(lower):])\n",
        "        else:\n",
        "            new_words.append(w)\n",
        "    return ' '.join(new_words)\n",
        "\n",
        "def hybrid_paraphrase(text, n=3):\n",
        "    original = str(text).strip()\n",
        "    if len(original) < 20:\n",
        "        return [original] * n\n",
        "\n",
        "    words = original.split()\n",
        "    if len(words) <= 8:  # kurze Texte → NUR SYNONYME!\n",
        "        results = set()\n",
        "        for _ in range(n):\n",
        "            variant = synonym_replace(original)\n",
        "            results.add(variant)\n",
        "        return list(results)[:n]\n",
        "\n",
        "    # Längere Texte → Synonyme + Umstrukturierung\n",
        "    results = set()\n",
        "    for _ in range(n):\n",
        "        step1 = synonym_replace(original)\n",
        "        # Nur leichte Umstellung bei längeren Texten\n",
        "        if len(step1.split()) > 10 and random.random() < 0.3:\n",
        "            sentences = re.split(r'(?<=[.!?])\\s+', step1)\n",
        "            if len(sentences) > 1:\n",
        "                random.shuffle(sentences)\n",
        "                step1 = ' '.join(sentences)\n",
        "        results.add(step1)\n",
        "\n",
        "    while len(results) < n:\n",
        "      results.add(original.replace(\"sehr\", \"wirklich\"))\n",
        "\n",
        "\n",
        "    return list(results)[:n]\n",
        "\n",
        "# erfahrungen_clean.csv laden, falls noch nicht vorhanden\n",
        "try:\n",
        "    df\n",
        "except NameError:\n",
        "    df = pd.read_csv(\"/content/drive/MyDrive/erfahrungen_clean.csv\")\n",
        "    df = df.dropna(subset=['Erfahrungsbericht des Nutzers']).reset_index(drop=True)\n",
        "    print(f\"{len(df)} Rezensionen geladen!\")\n",
        "\n",
        "# Test mit 10 Rezensionen aus erfahrungen_clean.csv\n",
        "test_indices = random.sample(range(len(df)), 10)\n",
        "print(f\"\\n10-TEST: HYBRID \\n\")\n",
        "print(\"=\"*90)\n",
        "\n",
        "for i, idx in enumerate(test_indices, 1):\n",
        "    text = df.iloc[idx]['Erfahrungsbericht des Nutzers']\n",
        "    print(f\"\\n{i}. ORIGINAL (Index {idx}):\")\n",
        "    print(text[:200] + (\"...\" if len(text) > 200 else \"\"))\n",
        "    print(\"\\n   PARAPHRASEN:\")\n",
        "    paras = hybrid_paraphrase(text, 3)\n",
        "    for j, p in enumerate(paras, 1):\n",
        "        print(f\"   {j}: {p[:200]}{'...' if len(p) > 200 else ''}\")\n",
        "    print(\"-\" * 90)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GP399bdAWkC5",
        "outputId": "f644efd7-6e36-42ab-c301-ce980e122e14"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "10-TEST: HYBRID (KEIN HÄNGEN MEHR!)\n",
            "\n",
            "==========================================================================================\n",
            "\n",
            "1. ORIGINAL (Index 2911):\n",
            "Sehr schön und modern\n",
            "\n",
            "   PARAPHRASEN:\n",
            "   1: Wirklich schön und modern\n",
            "   2: Sehr schön und modern\n",
            "------------------------------------------------------------------------------------------\n",
            "\n",
            "2. ORIGINAL (Index 2756):\n",
            "Teuer denn die Zimmer sind nicht sehr groß  und essen ist nicht lecker.\n",
            "\n",
            "   PARAPHRASEN:\n",
            "   1: Teuer denn die Zimmer sind nicht sehr groß und essen ist nicht lecker.\n",
            "   2: Teuer denn die Zimmer sind nicht wirklich groß und essen ist nicht lecker.\n",
            "   3: Teuer denn die Zimmer sind nicht wirklich groß und essen bleibt nicht lecker.\n",
            "------------------------------------------------------------------------------------------\n",
            "\n",
            "3. ORIGINAL (Index 5427):\n",
            "Sehr schön, machte einen sehr guten Eindruck. Personal schien sehr nett.\n",
            "\n",
            "   PARAPHRASEN:\n",
            "   1: Wirklich schön, machte einen besonders guten Eindruck. Personal schien sehr nett.\n",
            "   2: Sehr schön, machte einen sehr guten Eindruck. Personal schien besonders nett.\n",
            "   3: Wirklich schön, machte einen besonders guten Eindruck. Personal schien besonders nett.\n",
            "------------------------------------------------------------------------------------------\n",
            "\n",
            "4. ORIGINAL (Index 5213):\n",
            "Gute Anleitung von der Praxisanleiterin und ein gutes Team in allen Wohngruppen. Ich kann allen Schülern empfehlen\n",
            "\n",
            "   PARAPHRASEN:\n",
            "   1: Gute Anleitung von der Praxisanleiterin sowie ein gutes Team in allen Wohngruppen. Ich kann allen Schülern empfehlen\n",
            "   2: Gute Anleitung von der Praxisanleiterin – ein gutes Team in allen Wohngruppen. Ich kann allen Schülern empfehlen\n",
            "------------------------------------------------------------------------------------------\n",
            "\n",
            "5. ORIGINAL (Index 5445):\n",
            "Das Personal ist stehts hilfsbereit und kümmert sich hervorragend und individuel um die Bewohner. Speziel in der Demenzabteilung wo mein Vater einige Zeit wohnte ist mir das positive Klima aufgefallen...\n",
            "\n",
            "   PARAPHRASEN:\n",
            "   1: Das Personal ist stehts hilfsbereit sowie kümmert sich hervorragend und individuel um die Bewohner. Meine beiden Bewertung auch. Da ich ihn zu sehr unterschiedlichen Zeiten besucht habe, glaube ich ei...\n",
            "   2: Das Personal ist stehts hilfsbereit und kümmert sich hervorragend und individuel um die Bewohner. Speziel in der Demenzabteilung wo mein Vater einige Zeit wohnte ist mir das positive Klima aufgefallen...\n",
            "   3: Das Personal ist stehts hilfsbereit und kümmert sich hervorragend sowie individuel um die Senioren. Speziel in der Demenzabteilung wo mein Vater einige Zeit wohnte ist mir das positive Klima aufgefall...\n",
            "------------------------------------------------------------------------------------------\n",
            "\n",
            "6. ORIGINAL (Index 1799):\n",
            "Nette Leitung mit tollem Team , ansprechendes  Ambiente, familiäres Miteinander. Sehr zu empfehlen.\n",
            "\n",
            "   PARAPHRASEN:\n",
            "   1: Nette Leitung mit tollem Team , ansprechendes Ambiente, familiäres Miteinander. Sehr zu empfehlen.\n",
            "   2: Nette Leitung mit tollem Team , ansprechendes Ambiente, familiäres Miteinander. Wirklich zu empfehlen.\n",
            "------------------------------------------------------------------------------------------\n",
            "\n",
            "7. ORIGINAL (Index 4746):\n",
            "Sehr schlecht. Die Bewohner sind sich selbst überlassen. Ganz wenig Personal.\n",
            "\n",
            "   PARAPHRASEN:\n",
            "   1: Besonders schlecht. Die Senioren sind sich selbst überlassen. Ganz wenig Personal.\n",
            "   2: Sehr schlecht. Die Bewohner sind sich selbst überlassen. Ganz wenig Personal.\n",
            "------------------------------------------------------------------------------------------\n",
            "\n",
            "8. ORIGINAL (Index 4343):\n",
            "Schönes Haus,hell und freundlich. Hilfsbereites Personal. Da kann man sich wohl fühlen 😃\n",
            "\n",
            "   PARAPHRASEN:\n",
            "   1: Schönes Haus,hell sowie freundlich. Hilfsbereites Personal. Da kann man sich wohl fühlen 😃\n",
            "   2: Schönes Haus,hell und freundlich. Hilfsbereites Personal. Da kann man sich wohl fühlen 😃\n",
            "------------------------------------------------------------------------------------------\n",
            "\n",
            "9. ORIGINAL (Index 5801):\n",
            "Alles top\n",
            "\n",
            "   PARAPHRASEN:\n",
            "   1: Alles top\n",
            "   2: Alles top\n",
            "   3: Alles top\n",
            "------------------------------------------------------------------------------------------\n",
            "\n",
            "10. ORIGINAL (Index 3956):\n",
            "Schöner Ort, um einmal zu sehen, schöner Stadtpark!\n",
            "\n",
            "   PARAPHRASEN:\n",
            "   1: Schöner Ort, um einmal zu sehen, schöner Stadtpark!\n",
            "------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# finaler Batch: Alle Rezensionen aus \"efahrungen_clean.csv\" augmentieren\n",
        "print(f\"\\nSTART: Paraphrasierung aller {len(df)} Rezensionen -> {len(df)*3} Samples...\")\n",
        "aug_data = []\n",
        "\n",
        "for idx in tqdm(range(len(df)), desc=\"Augmentiere\", unit=\"text\"):\n",
        "    text = df.iloc[idx]['Erfahrungsbericht des Nutzers']\n",
        "    variants = hybrid_paraphrase(text, 3)\n",
        "    for v_id, para in enumerate(variants, 1):\n",
        "        aug_data.append({\n",
        "            'original_index': idx,\n",
        "            'original': text,\n",
        "            'paraphrase': para,\n",
        "            'variant_id': v_id\n",
        "        })\n",
        "\n",
        "# Speichern\n",
        "aug_df = pd.DataFrame(aug_data)\n",
        "output_path = \"/content/drive/MyDrive/ABSA_Paraphrase/augmented_erfahrungen.csv\"\n",
        "aug_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"\\nFERTIG!\")\n",
        "print(f\"→ {len(aug_df)} Paraphrasen gespeichert\")\n",
        "print(f\"→ Datei: {output_path}\")\n",
        "print(f\"→ Robuster Datensatz für Grok 3 Mini bei der ABSA vorbereitet!\")"
      ],
      "metadata": {
        "id": "KyC2F4CTW-2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "für Fine Tuning:\n",
        "Hugging Face: Fine-tune ein Grok-ähnliches Modell (z. B. \"xai-org/grok-1\" oder \"reedmayhew/Grok-3-gemma3-4B-distilled\" als Distillation von Grok 3). Das ist open-source und GitHub-freundlich.\n",
        "\n",
        "Code-Beispiel (Distillation von Grok 3 via API + Fine-Tuning auf Gemma-3 4B):\n"
      ],
      "metadata": {
        "id": "vfZm6aOvPbPD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Practices (aus Reddit, GitHub Blog, HF Docs):\n",
        "\n",
        "Lizenz: Füge eine LICENSE (z. B. Apache 2.0) hinzu, da Grok-Modelle proprietär sind – dein Fine-Tuning erbt das.\n",
        "Model Card: Erstelle eine (HF-Template: https://huggingface.co/docs/hub/model-cards) mit Details zu Daten (12.000 Rezensionen), Augmentation und Metriken.\n",
        "Datenschutz: Anonymisiere sensible Daten in der CSV (z. B. Namen entfernen), bevor du hochlädst – Pflegeberichte könnten personenbezogen sein (DSGVO-konform!).\n",
        "Versionskontrolle: Nutze GitHub Releases für große Dateien (z. B. Weights als Asset).\n",
        "Integration mit HF: Push zu Hugging Face Hub und verlinke im GitHub-Repo – HF ist GitHub-ähnlich und unterstützt Grok-Destillationen (z. B. \"reedmayhew/Grok-3-gemma3-4B-distilled\").\n",
        "\n",
        "\n",
        "\n",
        "3. Empfehlung für deine Bachelorarbeit\n",
        "\n",
        "Starte mit Option A/B: Prompt Engineering für schnelle Tests, dann Hugging Face für echtes Fine-Tuning (ca. 30–60 Min. in Colab mit GPU).\n",
        "GitHub-Repo als Portfolio: Lade Code, Skripte und Metriken hoch – das zeigt Reproduzierbarkeit. Vermeide rohe Weights (>100 MB) direkt; verlinke sie.\n",
        "Nächste Schritte: Hole dir einen xAI API-Key und HF-Token. Teste den Code in Colab.\n",
        "\n",
        "Falls du Hilfe beim Setup (z. B. API-Key, spezifischer Code-Fehler) brauchst oder mehr Details zu einer Option, lass es mich wissen!"
      ],
      "metadata": {
        "id": "V0ywlg4TQWl2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b06VD1uYFlSq"
      },
      "outputs": [],
      "source": [
        "# um damit zu beginnen: https://arxiv.org/html/2507.09485"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1MecGjdw--8eqoUfF53VL3Vja6L0ROuUF",
      "authorship_tag": "ABX9TyNOedEnJ2nU+11HMKTNAfNF"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}