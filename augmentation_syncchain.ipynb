{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup & Bibliotheken"
      ],
      "metadata": {
        "id": "N9BCNOvT1auc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Schritt 1: Deinstalliere alle problematischen Pakete\n",
        "!pip uninstall tensorflow tensorflow-text tf-keras tensorflow-decision-forests tensorflow-probability -y\n",
        "\n",
        "# Schritt 2: Installiere kompatible Versionen\n",
        "!pip install tensorflow==2.19.0 tensorflow-probability==0.25.0 tensorflow-text==2.19.0 tf-keras==2.19.0\n",
        "\n",
        "!pip install -q sentence-transformers transformers accelerate torch pandas tqdm\n",
        "\n",
        "# Schritt 3: Unterdr√ºcke Warnungen (f√ºr parakeet und CUDA)\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Unterdr√ºckt TensorFlow-Warnungen\n",
        "\n",
        "# Schritt 4: Teste den Import\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "print(\"Import erfolgreich!\")\n",
        "\n",
        "# Schritt 5: Teste tensorflow_probability\n",
        "import tensorflow_probability as tfp\n",
        "print(f\"TensorFlow Probability Version: {tfp.__version__}\")\n",
        "!pip install transformers torch pandas tqdm -q"
      ],
      "metadata": {
        "id": "nhCh6T2Crh3u",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import platform\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import tensorflow_probability as tfp\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from google.colab import files, drive\n",
        "from datetime import datetime\n",
        "import time\n",
        "import shutil\n",
        "import re\n",
        "\n",
        "from google.colab import drive\n",
        "\n"
      ],
      "metadata": {
        "id": "VhqmpRX0F-WE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def smartEncoding():\n",
        "  plt = platform.system\n",
        "  if plt == \"Windows\":\n",
        "    return \"utf-8-sig\"\n",
        "  else:\n",
        "    return \"utf-8\""
      ],
      "metadata": {
        "id": "NqgyTXTb2AqA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6sxMd7fsqOR"
      },
      "source": [
        "# Gew√§hlte xlsl Datei in csv Datei umwandeln und umbenennen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaFrz040hSDp",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "\n",
        "read_file = pd.DataFrame(pd.read_excel('/content/drive/My Drive/Google_Rezensionen_qualit√§tsgesichert_2023_12_19 (1).xlsx'))\n",
        "read_file.to_csv(\"Google_Rezensionen_qualit√§tsgesichert_2023_12_19 (1).csv\", index = False, header = True, encoding=smartEncoding())\n",
        "df = pd.DataFrame(pd.read_csv(\"Google_Rezensionen_qualit√§tsgesichert_2023_12_19 (1).csv\"))\n",
        "#print(df.head)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "q4FshCWEs1-J"
      },
      "outputs": [],
      "source": [
        "#w√§hle relevante Spalten\n",
        "gewaehlte_spalten = df[[\"Erfahrungsbericht des Nutzers\" , \"Zufallszahl\"]]\n",
        "\n",
        "#speichere sie in neue csv datei\n",
        "gewaehlte_spalten.to_csv(\"/content/drive/My Drive/erfahrungen_gefiltert.csv\", index = False)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nfd5RwKdjNQv"
      },
      "source": [
        "# Datenbereinigung"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "etZLmS_XhRox",
        "outputId": "202314f6-980c-4370-da37-4a14abae9c88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FINAL: 6453 Reihen\n",
            "100 Zufallsberichte!\n"
          ]
        }
      ],
      "source": [
        "erfahrungen_gefiltert = pd.read_csv(\"/content/drive/My Drive/erfahrungen_gefiltert.csv\")\n",
        "# dropna() entfernt NaN-Reihen aus anderen Spalten\n",
        "erfahrungen_gefiltert.dropna(subset=['Erfahrungsbericht des Nutzers'], inplace=True)\n",
        "# leere strings entfernen\n",
        "erfahrungen_gefiltert.drop_duplicates(inplace=True)\n",
        "#speichern\n",
        "erfahrungen_gefiltert.to_csv(\"/content/drive/My Drive/erfahrungen_clean.csv\", index=False)\n",
        "print(f\"FINAL: {len(erfahrungen_gefiltert)} Reihen\")\n",
        "\n",
        "\n",
        "#speichere sie in neue csv datei\n",
        "gewaehlte_spalten.to_csv(\"/content/drive/My Drive/erfahrungen_clean.csv\", index = False)\n",
        "\n",
        "\n",
        "#zuf√§llig n = 100 Berichte f√ºr erfahrungen_final.csv ausw√§hlen\n",
        "erfahrungen_clean = pd.read_csv(\"/content/drive/My Drive/erfahrungen_clean.csv\")\n",
        "# dropna() entfernt NaN-Reihen aus anderen Spalten\n",
        "erfahrungen_clean.dropna(subset=['Erfahrungsbericht des Nutzers'], inplace=True)\n",
        "# leere strings entfernen\n",
        "erfahrungen_clean.drop_duplicates(inplace=True)\n",
        "erfahrungen_clean.to_csv(\"/content/drive/My Drive/erfahrungen_clean.csv\", index = False)\n",
        "\n",
        "# INDEX-Nummern zuf√§llig w√§hlen\n",
        "zufalls_index = random.sample(range(len(erfahrungen_clean)), k=100)\n",
        "zufall_100 = erfahrungen_clean.iloc[zufalls_index]\n",
        "\n",
        "\n",
        "\n",
        "#speichern (NUR 100!)\n",
        "zufall_100.to_csv(\"/content/drive/My Drive/zufall_100_berichte.csv\", index=False)\n",
        "\n",
        "print(f\"{len(zufall_100)} Zufallsberichte!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPzrsAJjFsW2"
      },
      "source": [
        "# **Datenaugmentation und Syn-Chain-Methode**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datenaugmentation mit Trainingsdaten (ca. 11.900 Rezensionen)"
      ],
      "metadata": {
        "id": "oDX0N5V-IhnY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paraphrasieren"
      ],
      "metadata": {
        "id": "8p0Z4ygud_8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Google Drive mounten\n",
        "drive.mount('/content/drive')\n",
        "SAVE_PATH = '/content/drive/MyDrive/ABSA_Paraphrase/'\n",
        "os.makedirs(SAVE_PATH, exist_ok=True)\n",
        "\n",
        "print(\"Ordner & Bibliotheken geladen!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkXOEJrCaMv2",
        "outputId": "d19cc511-8f02-449b-8119-72591ece579e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Ordner & Bibliotheken geladen!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vllt. ist das die beste L√∂sung?"
      ],
      "metadata": {
        "id": "sExwqN0MXBMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paraphrasierung\n",
        "\n",
        "SYNONYMS = {\n",
        "    \"schmutzig\": [\"dreckig\", \"unhygienisch\", \"unrein\" , \"unsauber\", \"verschmutzt\", \"versifft\", \"gammelig\", \"schmuddelig\"],\n",
        "    \"hygienisch\": [\"sauber\", \"rein\", \"keimfrei\", \"ges√§ubert\", \"picobello\", \"blitzeblank\"],\n",
        "    \"arbeite\": [\"bin t√§tig\", \"besch√§ftigt\", \"bin angestellt\"],\n",
        "    \"seit\": [\"seit etwa\", \"schon seit\"],\n",
        "    \"im\": [\"in\", \"bei\"],\n",
        "    \"und\": [\"sowie\", \"‚Äì\", \"&\"],\n",
        "    \"meine\": [\"meine beiden\"],\n",
        "    \"waren\": [\"lebten\", \"wohnten\"],\n",
        "    \"dort\": [\"dort\", \"im Heim\", \"in der Einrichung\"],\n",
        "    \"ist\": [\"bleibt\"],\n",
        "    \"sehr\": [\"wirklich\", \"besonders\"],\n",
        "    \"kollegial\": [\"freundschaftlich\", \"kameradschaftlich\", \"wie ein guter Kollege\"],\n",
        "    \"betreuung\": [\"Pflege\", \"F√ºrsorge\", \"Hilfe\", \"Obhut\", \"Unterst√ºtzung\"],\n",
        "    \"bewohner\": [\"Senioren\", \"Pflegebed√ºrftige\"],\n",
        "    \"essen\": [\"Verpflegung\", \"Verk√∂stigung\", \"Speisen\", \"Mahl\" , \"Nahrung\"],\n",
        "    \"fest\": [\"Feier\", \"Party\" \"Fete\"],\n",
        "    \"beliebt\": [\"gesch√§tzt\", \"begehrt\", \"wird gemocht\"],\n",
        "    \"schlecht\": [\"mies\", \"mieserabel\", \"schrecklich\" \"mangelhaft\", \"unkorrekt\", \"daneben\"],\n",
        "    \"warum\": [\"weshalb\", \"wieso\"],\n",
        "    \"gut\": [\"angenehm\"],\n",
        "    \"top\": [\"super\", \"toll\", \"einwandfrei\", \"hammer\"],\n",
        "    \"sauber\": [\"ordentlich\", \"gepflegt\"],\n",
        "    \"lecker\": [\"k√∂stlich\", \"schmackhaft\", \"gut\"]\n",
        "\n",
        "}# kann noch erweitert werden!\n",
        "\n",
        "def synonym_replace(text):\n",
        "    words = text.split()\n",
        "    new_words = []\n",
        "    for w in words:\n",
        "        lower = w.lower().rstrip('.,!?')\n",
        "        if lower in SYNONYMS and random.random() < 0.5:\n",
        "            repl = random.choice(SYNONYMS[lower])\n",
        "            if w[0].isupper(): repl = repl.capitalize()\n",
        "            new_words.append(repl + w[len(lower):])\n",
        "        else:\n",
        "            new_words.append(w)\n",
        "    return ' '.join(new_words)\n",
        "\n",
        "def hybrid_paraphrase(text, n=3):\n",
        "    original = str(text).strip()\n",
        "    if len(original) < 20:\n",
        "        return [original] * n\n",
        "\n",
        "    words = original.split()\n",
        "    if len(words) <= 8:  # kurze Texte ‚Üí NUR SYNONYME!\n",
        "        results = set()\n",
        "        for _ in range(n):\n",
        "            variant = synonym_replace(original)\n",
        "            results.add(variant)\n",
        "        return list(results)[:n]\n",
        "\n",
        "    # L√§ngere Texte ‚Üí Synonyme + Umstrukturierung\n",
        "    results = set()\n",
        "    for _ in range(n):\n",
        "        step1 = synonym_replace(original)\n",
        "        # Nur leichte Umstellung bei l√§ngeren Texten\n",
        "        if len(step1.split()) > 10 and random.random() < 0.3:\n",
        "            sentences = re.split(r'(?<=[.!?])\\s+', step1)\n",
        "            if len(sentences) > 1:\n",
        "                random.shuffle(sentences)\n",
        "                step1 = ' '.join(sentences)\n",
        "        results.add(step1)\n",
        "\n",
        "    while len(results) < n:\n",
        "      results.add(original.replace(\"sehr\", \"wirklich\"))\n",
        "\n",
        "\n",
        "    return list(results)[:n]\n",
        "\n",
        "# erfahrungen_clean.csv laden, falls noch nicht vorhanden\n",
        "try:\n",
        "    df\n",
        "except NameError:\n",
        "    df = pd.read_csv(\"/content/drive/MyDrive/erfahrungen_clean.csv\")\n",
        "    df = df.dropna(subset=['Erfahrungsbericht des Nutzers']).reset_index(drop=True)\n",
        "    print(f\"{len(df)} Rezensionen geladen!\")\n",
        "\n",
        "# Test mit 10 Rezensionen aus erfahrungen_clean.csv\n",
        "test_indices = random.sample(range(len(df)), 10)\n",
        "print(f\"\\n10-TEST: HYBRID \\n\")\n",
        "print(\"=\"*90)\n",
        "\n",
        "for i, idx in enumerate(test_indices, 1):\n",
        "    text = df.iloc[idx]['Erfahrungsbericht des Nutzers']\n",
        "    print(f\"\\n{i}. ORIGINAL (Index {idx}):\")\n",
        "    print(text[:200] + (\"...\" if len(text) > 200 else \"\"))\n",
        "    print(\"\\n   PARAPHRASEN:\")\n",
        "    paras = hybrid_paraphrase(text, 3)\n",
        "    for j, p in enumerate(paras, 1):\n",
        "        print(f\"   {j}: {p[:200]}{'...' if len(p) > 200 else ''}\")\n",
        "    print(\"-\" * 90)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GP399bdAWkC5",
        "outputId": "f644efd7-6e36-42ab-c301-ce980e122e14"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "10-TEST: HYBRID (KEIN H√ÑNGEN MEHR!)\n",
            "\n",
            "==========================================================================================\n",
            "\n",
            "1. ORIGINAL (Index 2911):\n",
            "Sehr sch√∂n und modern\n",
            "\n",
            "   PARAPHRASEN:\n",
            "   1: Wirklich sch√∂n und modern\n",
            "   2: Sehr sch√∂n und modern\n",
            "------------------------------------------------------------------------------------------\n",
            "\n",
            "2. ORIGINAL (Index 2756):\n",
            "Teuer denn die Zimmer sind nicht sehr gro√ü  und essen ist nicht lecker.\n",
            "\n",
            "   PARAPHRASEN:\n",
            "   1: Teuer denn die Zimmer sind nicht sehr gro√ü und essen ist nicht lecker.\n",
            "   2: Teuer denn die Zimmer sind nicht wirklich gro√ü und essen ist nicht lecker.\n",
            "   3: Teuer denn die Zimmer sind nicht wirklich gro√ü und essen bleibt nicht lecker.\n",
            "------------------------------------------------------------------------------------------\n",
            "\n",
            "3. ORIGINAL (Index 5427):\n",
            "Sehr sch√∂n, machte einen sehr guten Eindruck. Personal schien sehr nett.\n",
            "\n",
            "   PARAPHRASEN:\n",
            "   1: Wirklich sch√∂n, machte einen besonders guten Eindruck. Personal schien sehr nett.\n",
            "   2: Sehr sch√∂n, machte einen sehr guten Eindruck. Personal schien besonders nett.\n",
            "   3: Wirklich sch√∂n, machte einen besonders guten Eindruck. Personal schien besonders nett.\n",
            "------------------------------------------------------------------------------------------\n",
            "\n",
            "4. ORIGINAL (Index 5213):\n",
            "Gute Anleitung von der Praxisanleiterin und ein gutes Team in allen Wohngruppen. Ich kann allen Sch√ºlern empfehlen\n",
            "\n",
            "   PARAPHRASEN:\n",
            "   1: Gute Anleitung von der Praxisanleiterin sowie ein gutes Team in allen Wohngruppen. Ich kann allen Sch√ºlern empfehlen\n",
            "   2: Gute Anleitung von der Praxisanleiterin ‚Äì ein gutes Team in allen Wohngruppen. Ich kann allen Sch√ºlern empfehlen\n",
            "------------------------------------------------------------------------------------------\n",
            "\n",
            "5. ORIGINAL (Index 5445):\n",
            "Das Personal ist stehts hilfsbereit und k√ºmmert sich hervorragend und individuel um die Bewohner. Speziel in der Demenzabteilung wo mein Vater einige Zeit wohnte ist mir das positive Klima aufgefallen...\n",
            "\n",
            "   PARAPHRASEN:\n",
            "   1: Das Personal ist stehts hilfsbereit sowie k√ºmmert sich hervorragend und individuel um die Bewohner. Meine beiden Bewertung auch. Da ich ihn zu sehr unterschiedlichen Zeiten besucht habe, glaube ich ei...\n",
            "   2: Das Personal ist stehts hilfsbereit und k√ºmmert sich hervorragend und individuel um die Bewohner. Speziel in der Demenzabteilung wo mein Vater einige Zeit wohnte ist mir das positive Klima aufgefallen...\n",
            "   3: Das Personal ist stehts hilfsbereit und k√ºmmert sich hervorragend sowie individuel um die Senioren. Speziel in der Demenzabteilung wo mein Vater einige Zeit wohnte ist mir das positive Klima aufgefall...\n",
            "------------------------------------------------------------------------------------------\n",
            "\n",
            "6. ORIGINAL (Index 1799):\n",
            "Nette Leitung mit tollem Team , ansprechendes  Ambiente, famili√§res Miteinander. Sehr zu empfehlen.\n",
            "\n",
            "   PARAPHRASEN:\n",
            "   1: Nette Leitung mit tollem Team , ansprechendes Ambiente, famili√§res Miteinander. Sehr zu empfehlen.\n",
            "   2: Nette Leitung mit tollem Team , ansprechendes Ambiente, famili√§res Miteinander. Wirklich zu empfehlen.\n",
            "------------------------------------------------------------------------------------------\n",
            "\n",
            "7. ORIGINAL (Index 4746):\n",
            "Sehr schlecht. Die Bewohner sind sich selbst √ºberlassen. Ganz wenig Personal.\n",
            "\n",
            "   PARAPHRASEN:\n",
            "   1: Besonders schlecht. Die Senioren sind sich selbst √ºberlassen. Ganz wenig Personal.\n",
            "   2: Sehr schlecht. Die Bewohner sind sich selbst √ºberlassen. Ganz wenig Personal.\n",
            "------------------------------------------------------------------------------------------\n",
            "\n",
            "8. ORIGINAL (Index 4343):\n",
            "Sch√∂nes Haus,hell und freundlich. Hilfsbereites Personal. Da kann man sich wohl f√ºhlen üòÉ\n",
            "\n",
            "   PARAPHRASEN:\n",
            "   1: Sch√∂nes Haus,hell sowie freundlich. Hilfsbereites Personal. Da kann man sich wohl f√ºhlen üòÉ\n",
            "   2: Sch√∂nes Haus,hell und freundlich. Hilfsbereites Personal. Da kann man sich wohl f√ºhlen üòÉ\n",
            "------------------------------------------------------------------------------------------\n",
            "\n",
            "9. ORIGINAL (Index 5801):\n",
            "Alles top\n",
            "\n",
            "   PARAPHRASEN:\n",
            "   1: Alles top\n",
            "   2: Alles top\n",
            "   3: Alles top\n",
            "------------------------------------------------------------------------------------------\n",
            "\n",
            "10. ORIGINAL (Index 3956):\n",
            "Sch√∂ner Ort, um einmal zu sehen, sch√∂ner Stadtpark!\n",
            "\n",
            "   PARAPHRASEN:\n",
            "   1: Sch√∂ner Ort, um einmal zu sehen, sch√∂ner Stadtpark!\n",
            "------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# finaler Batch: Alle Rezensionen aus \"efahrungen_clean.csv\" augmentieren\n",
        "print(f\"\\nSTART: Paraphrasierung aller {len(df)} Rezensionen -> {len(df)*3} Samples...\")\n",
        "aug_data = []\n",
        "\n",
        "for idx in tqdm(range(len(df)), desc=\"Augmentiere\", unit=\"text\"):\n",
        "    text = df.iloc[idx]['Erfahrungsbericht des Nutzers']\n",
        "    variants = hybrid_paraphrase(text, 3)\n",
        "    for v_id, para in enumerate(variants, 1):\n",
        "        aug_data.append({\n",
        "            'original_index': idx,\n",
        "            'original': text,\n",
        "            'paraphrase': para,\n",
        "            'variant_id': v_id\n",
        "        })\n",
        "\n",
        "# Speichern\n",
        "aug_df = pd.DataFrame(aug_data)\n",
        "output_path = \"/content/drive/MyDrive/ABSA_Paraphrase/augmented_erfahrungen.csv\"\n",
        "aug_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"\\nFERTIG!\")\n",
        "print(f\"‚Üí {len(aug_df)} Paraphrasen gespeichert\")\n",
        "print(f\"‚Üí Datei: {output_path}\")\n",
        "print(f\"‚Üí Robuster Datensatz f√ºr Grok 3 Mini bei der ABSA vorbereitet!\")"
      ],
      "metadata": {
        "id": "KyC2F4CTW-2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "f√ºr Fine Tuning:\n",
        "Hugging Face: Fine-tune ein Grok-√§hnliches Modell (z. B. \"xai-org/grok-1\" oder \"reedmayhew/Grok-3-gemma3-4B-distilled\" als Distillation von Grok 3). Das ist open-source und GitHub-freundlich.\n",
        "\n",
        "Code-Beispiel (Distillation von Grok 3 via API + Fine-Tuning auf Gemma-3 4B):\n"
      ],
      "metadata": {
        "id": "vfZm6aOvPbPD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Practices (aus Reddit, GitHub Blog, HF Docs):\n",
        "\n",
        "Lizenz: F√ºge eine LICENSE (z. B. Apache 2.0) hinzu, da Grok-Modelle propriet√§r sind ‚Äì dein Fine-Tuning erbt das.\n",
        "Model Card: Erstelle eine (HF-Template: https://huggingface.co/docs/hub/model-cards) mit Details zu Daten (12.000 Rezensionen), Augmentation und Metriken.\n",
        "Datenschutz: Anonymisiere sensible Daten in der CSV (z. B. Namen entfernen), bevor du hochl√§dst ‚Äì Pflegeberichte k√∂nnten personenbezogen sein (DSGVO-konform!).\n",
        "Versionskontrolle: Nutze GitHub Releases f√ºr gro√üe Dateien (z. B. Weights als Asset).\n",
        "Integration mit HF: Push zu Hugging Face Hub und verlinke im GitHub-Repo ‚Äì HF ist GitHub-√§hnlich und unterst√ºtzt Grok-Destillationen (z. B. \"reedmayhew/Grok-3-gemma3-4B-distilled\").\n",
        "\n",
        "\n",
        "\n",
        "3. Empfehlung f√ºr deine Bachelorarbeit\n",
        "\n",
        "Starte mit Option A/B: Prompt Engineering f√ºr schnelle Tests, dann Hugging Face f√ºr echtes Fine-Tuning (ca. 30‚Äì60 Min. in Colab mit GPU).\n",
        "GitHub-Repo als Portfolio: Lade Code, Skripte und Metriken hoch ‚Äì das zeigt Reproduzierbarkeit. Vermeide rohe Weights (>100 MB) direkt; verlinke sie.\n",
        "N√§chste Schritte: Hole dir einen xAI API-Key und HF-Token. Teste den Code in Colab.\n",
        "\n",
        "Falls du Hilfe beim Setup (z. B. API-Key, spezifischer Code-Fehler) brauchst oder mehr Details zu einer Option, lass es mich wissen!"
      ],
      "metadata": {
        "id": "V0ywlg4TQWl2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b06VD1uYFlSq"
      },
      "outputs": [],
      "source": [
        "# um damit zu beginnen: https://arxiv.org/html/2507.09485"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1MecGjdw--8eqoUfF53VL3Vja6L0ROuUF",
      "authorship_tag": "ABX9TyNOedEnJ2nU+11HMKTNAfNF"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}