{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9BCNOvT1auc"
      },
      "source": [
        "# Setup & Bibliotheken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "nhCh6T2Crh3u"
      },
      "outputs": [],
      "source": [
        "# Schritt 1: Deinstalliere alle problematischen Pakete\n",
        "!pip uninstall tensorflow tensorflow-text tf-keras tensorflow-decision-forests tensorflow-probability -y\n",
        "\n",
        "# Schritt 2: Installiere kompatible Versionen\n",
        "!pip install tensorflow==2.19.0 tensorflow-probability==0.25.0 tensorflow-text==2.19.0 tf-keras==2.19.0\n",
        "\n",
        "!pip install -q sentence-transformers transformers accelerate torch pandas tqdm\n",
        "\n",
        "# Schritt 3: Unterdrücke Warnungen (für parakeet und CUDA)\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Unterdrückt TensorFlow-Warnungen\n",
        "\n",
        "# Schritt 4: Teste den Import\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "print(\"Import erfolgreich!\")\n",
        "\n",
        "# Schritt 5: Teste tensorflow_probability\n",
        "import tensorflow_probability as tfp\n",
        "print(f\"TensorFlow Probability Version: {tfp.__version__}\")\n",
        "!pip install transformers torch pandas tqdm -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "VhqmpRX0F-WE"
      },
      "outputs": [],
      "source": [
        "\n",
        "import platform\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import tensorflow_probability as tfp\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from google.colab import files, drive\n",
        "from datetime import datetime\n",
        "import time\n",
        "import shutil\n",
        "import re\n",
        "\n",
        "from google.colab import drive\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NqgyTXTb2AqA"
      },
      "outputs": [],
      "source": [
        "def smartEncoding():\n",
        "  plt = platform.system\n",
        "  if plt == \"Windows\":\n",
        "    return \"utf-8-sig\"\n",
        "  else:\n",
        "    return \"utf-8\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6sxMd7fsqOR"
      },
      "source": [
        "# Gewählte xlsl Datei in csv Datei umwandeln und umbenennen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "VaFrz040hSDp"
      },
      "outputs": [],
      "source": [
        "\n",
        "read_file = pd.DataFrame(pd.read_excel('/content/drive/My Drive/Google_Rezensionen_qualitätsgesichert_2023_12_19 (1).xlsx'))\n",
        "read_file.to_csv(\"Google_Rezensionen_qualitätsgesichert_2023_12_19 (1).csv\", index = False, header = True, encoding=smartEncoding())\n",
        "df = pd.DataFrame(pd.read_csv(\"Google_Rezensionen_qualitätsgesichert_2023_12_19 (1).csv\"))\n",
        "#print(df.head)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "q4FshCWEs1-J"
      },
      "outputs": [],
      "source": [
        "#wähle relevante Spalten\n",
        "gewaehlte_spalten = df[[\"Erfahrungsbericht des Nutzers\" , \"Zufallszahl\"]]\n",
        "\n",
        "#speichere sie in neue csv datei\n",
        "gewaehlte_spalten.to_csv(\"/content/drive/My Drive/erfahrungen_gefiltert.csv\", index = False)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nfd5RwKdjNQv"
      },
      "source": [
        "# Datenbereinigung"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "etZLmS_XhRox",
        "outputId": "202314f6-980c-4370-da37-4a14abae9c88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FINAL: 6453 Reihen\n",
            "100 Zufallsberichte!\n"
          ]
        }
      ],
      "source": [
        "erfahrungen_gefiltert = pd.read_csv(\"/content/drive/My Drive/erfahrungen_gefiltert.csv\")\n",
        "# dropna() entfernt NaN-Reihen aus anderen Spalten\n",
        "erfahrungen_gefiltert.dropna(subset=['Erfahrungsbericht des Nutzers'], inplace=True)\n",
        "# leere strings entfernen\n",
        "erfahrungen_gefiltert.drop_duplicates(inplace=True)\n",
        "#speichern\n",
        "erfahrungen_gefiltert.to_csv(\"/content/drive/My Drive/erfahrungen_clean.csv\", index=False)\n",
        "print(f\"FINAL: {len(erfahrungen_gefiltert)} Reihen\")\n",
        "\n",
        "\n",
        "#speichere sie in neue csv datei\n",
        "gewaehlte_spalten.to_csv(\"/content/drive/My Drive/erfahrungen_clean.csv\", index = False)\n",
        "\n",
        "\n",
        "#zufällig n = 100 Berichte für erfahrungen_final.csv auswählen\n",
        "erfahrungen_clean = pd.read_csv(\"/content/drive/My Drive/erfahrungen_clean.csv\")\n",
        "# dropna() entfernt NaN-Reihen aus anderen Spalten\n",
        "erfahrungen_clean.dropna(subset=['Erfahrungsbericht des Nutzers'], inplace=True)\n",
        "# leere strings entfernen\n",
        "erfahrungen_clean.drop_duplicates(inplace=True)\n",
        "erfahrungen_clean.to_csv(\"/content/drive/My Drive/erfahrungen_clean.csv\", index = False)\n",
        "\n",
        "# INDEX-Nummern zufällig wählen\n",
        "zufalls_index = random.sample(range(len(erfahrungen_clean)), k=100)\n",
        "zufall_100 = erfahrungen_clean.iloc[zufalls_index]\n",
        "\n",
        "\n",
        "\n",
        "#speichern (NUR 100!)\n",
        "zufall_100.to_csv(\"/content/drive/My Drive/zufall_100_berichte.csv\", index=False)\n",
        "\n",
        "print(f\"{len(zufall_100)} Zufallsberichte!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPzrsAJjFsW2"
      },
      "source": [
        "# **Datenaugmentation und Syn-Chain-Methode**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDX0N5V-IhnY"
      },
      "source": [
        "## Datenaugmentation mit Trainingsdaten (ca. 11.900 Rezensionen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8p0Z4ygud_8_"
      },
      "source": [
        "## Paraphrasieren"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkXOEJrCaMv2",
        "outputId": "d19cc511-8f02-449b-8119-72591ece579e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Ordner & Bibliotheken geladen!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Google Drive mounten\n",
        "drive.mount('/content/drive')\n",
        "SAVE_PATH = '/content/drive/MyDrive/ABSA_Paraphrase/'\n",
        "os.makedirs(SAVE_PATH, exist_ok=True)\n",
        "\n",
        "print(\"Ordner & Bibliotheken geladen!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Beste Lösung bislang"
      ],
      "metadata": {
        "id": "fttVfq7ddRec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def smartEncoding():\n",
        "  plt = platform.system\n",
        "  if plt == \"Windows\":\n",
        "    return \"utf-8-sig\"\n",
        "  else:\n",
        "    return \"utf-8\"\n",
        "\n",
        "# Paraphrasierung\n",
        "\n",
        "SYNONYMS = {\n",
        "    \"schmutzig\": [\"dreckig\", \"unhygienisch\", \"unrein\" , \"unsauber\", \"verschmutzt\", \"versifft\", \"gammelig\", \"schmuddelig\"],\n",
        "    \"hygienisch\": [\"sauber\", \"rein\", \"keimfrei\", \"gesäubert\", \"picobello\", \"blitzeblank\"],\n",
        "    \"arbeite\": [\"bin tätig\", \"beschäftigt\", \"bin angestellt\"],\n",
        "    \"seit\": [\"seit etwa\", \"schon seit\", \"seit circa\"],\n",
        "    \"im\": [\"in\", \"bei\"],\n",
        "    \"und\": [\"sowie\", \"–\", \"&\"],\n",
        "    \"meine\": [\"meine beiden\"],\n",
        "    \"waren\": [\"lebten\", \"wohnten\"],\n",
        "    \"dort\": [\"dort\", \"im Heim\", \"in der Einrichung\"],\n",
        "    \"ist\": [\"bleibt\"],\n",
        "    \"sehr\": [\"wirklich\", \"besonders\"],\n",
        "    \"kollegial\": [\"freundschaftlich\", \"kameradschaftlich\", \"wie ein guter Kollege\"],\n",
        "    \"betreuung\": [\"Pflege\", \"Fürsorge\", \"Hilfe\", \"Obhut\", \"Unterstützung\"],\n",
        "    \"bewohner\": [\"Senioren\", \"Pflegebedürftige\"],\n",
        "    \"essen\": [ \"Speisen\", \"Nahrung\"],\n",
        "    \"fest\": [\"Feier\", \"Party\" \"Fete\"],\n",
        "    \"beliebt\": [\"geschätzt\", \"begehrt\", \"wird gemocht\"],\n",
        "    \"schlecht\": [\"mies\", \"mieserabel\", \"schrecklich\" \"mangelhaft\", \"unkorrekt\", \"daneben\"],\n",
        "    \"warum\": [\"weshalb\", \"wieso\"],\n",
        "    \"gut\": [\"angenehm\"],\n",
        "    \"top\": [\"super\", \"toll\", \"einwandfrei\", \"hammer\"],\n",
        "    \"sauber\": [\"ordentlich\", \"gepflegt\"],\n",
        "    \"lecker\": [\"köstlich\", \"schmackhaft\", \"gut\"],\n",
        "    \"okay\": [\"in Ordnung\", \"befriedigend\"]\n",
        "\n",
        "}# kann noch erweitert werden!\n",
        "\n",
        "def synonym_replace(text):\n",
        "    words = text.split()\n",
        "    new_words = []\n",
        "    for w in words:\n",
        "        lower = w.lower().rstrip('.,!?')\n",
        "        if lower in SYNONYMS and random.random() < 0.5:\n",
        "            repl = random.choice(SYNONYMS[lower])\n",
        "            if w[0].isupper(): repl = repl.capitalize()\n",
        "            new_words.append(repl + w[len(lower):])\n",
        "        else:\n",
        "            new_words.append(w)\n",
        "    return ' '.join(new_words)\n",
        "\n",
        "def hybrid_paraphrase(text, n=3):\n",
        "    original = str(text).strip()\n",
        "    if len(original) < 20:\n",
        "        return [original] * n\n",
        "\n",
        "    results = set()\n",
        "    max_attempts = n * 5  # max. 15 Versuche\n",
        "\n",
        "    for _ in range(max_attempts):\n",
        "        if len(results) >= n:\n",
        "            break\n",
        "\n",
        "        step1 = synonym_replace(original)\n",
        "        if len(step1.split()) > 10 and random.random() < 0.3:\n",
        "            sentences = re.split(r'(?<=[.!?])\\s+', step1)\n",
        "            if len(sentences) > 1:\n",
        "                random.shuffle(sentences)\n",
        "                step1 = ' '.join(sentences)\n",
        "        results.add(step1)\n",
        "\n",
        "    # garantierte Ausgabe,damit Prgramm an dieser schleife nicht hängen bleibt\n",
        "    result_list = list(results)\n",
        "    while len(result_list) < n:\n",
        "        result_list.append(original)\n",
        "\n",
        "    return result_list[:n]\n",
        "\n",
        "# erfahrungen_clean.csv laden, falls noch nicht vorhanden\n",
        "try:\n",
        "    df\n",
        "except NameError:\n",
        "    df = pd.read_csv(\"erfahrungen_clean.csv\")\n",
        "    df = df.dropna(subset=['Erfahrungsbericht des Nutzers']).reset_index(drop=True)\n",
        "    print(f\"{len(df)} Rezensionen geladen!\")\n",
        "\n",
        "# Test mit 10 Rezensionen aus erfahrungen_clean.csv\n",
        "test_indices = random.sample(range(len(df)), 10)\n",
        "print(f\"\\n10-TEST: HYBRID \\n\")\n",
        "print(\"=\"*90)\n",
        "\n",
        "for i, idx in enumerate(test_indices, 1):\n",
        "    text = str(df.iloc[idx]['Erfahrungsbericht des Nutzers'])\n",
        "    print(f\"\\n{i}. ORIGINAL (Index {idx}):\")\n",
        "    print(text[:200] + (\"...\" if len(text) > 200 else \"\"))\n",
        "    print(\"\\n   PARAPHRASEN:\")\n",
        "    paras = hybrid_paraphrase(text, 3)\n",
        "    print(\"Wir sind NACH 'paras'\")\n",
        "    for j, p in enumerate(paras, 1):\n",
        "        print(f\"   {j}: {p[:200]}{'...' if len(p) > 200 else ''}\")\n",
        "    print(\"-\" * 90)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4243f5f-491c-4408-8d84-d8d5c20adc12",
        "collapsed": true,
        "id": "J03xVNBOdTXH"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "10-TEST: HYBRID \n",
            "\n",
            "==========================================================================================\n",
            "\n",
            "1. ORIGINAL (Index 1893):\n",
            "Freundliche, schnelle, unbürokratische Hilfe, schöne Einrichtung mit viel Aktivitäten für Senioren, guter Mittagstisch, nette Atmosphäre, ruhige Lage\n",
            "\n",
            "   PARAPHRASEN:\n",
            "Wir sind NACH 'paras'\n",
            "   1: Freundliche, schnelle, unbürokratische Hilfe, schöne Einrichtung mit viel Aktivitäten für Senioren, guter Mittagstisch, nette Atmosphäre, ruhige Lage\n",
            "   2: Freundliche, schnelle, unbürokratische Hilfe, schöne Einrichtung mit viel Aktivitäten für Senioren, guter Mittagstisch, nette Atmosphäre, ruhige Lage\n",
            "   3: Freundliche, schnelle, unbürokratische Hilfe, schöne Einrichtung mit viel Aktivitäten für Senioren, guter Mittagstisch, nette Atmosphäre, ruhige Lage\n",
            "------------------------------------------------------------------------------------------\n",
            "\n",
            "2. ORIGINAL (Index 3213):\n",
            "Wer dieses Haus schlecht redet, hat keinen Einblick wie es in anderen Einrichtungen aussieht. Es ist einfach rundum ein tolles Haus\n",
            "\n",
            "   PARAPHRASEN:\n",
            "Wir sind NACH 'paras'\n",
            "   1: Wer dieses Haus schlecht redet, hat keinen Einblick wie es in anderen Einrichtungen aussieht. Es bleibt einfach rundum ein tolles Haus\n",
            "   2: Wer dieses Haus unkorrekt redet, hat keinen Einblick wie es in anderen Einrichtungen aussieht. Es ist einfach rundum ein tolles Haus\n",
            "   3: Wer dieses Haus daneben redet, hat keinen Einblick wie es in anderen Einrichtungen aussieht. Es bleibt einfach rundum ein tolles Haus\n",
            "------------------------------------------------------------------------------------------\n",
            "\n",
            "3. ORIGINAL (Index 6422):\n",
            "Ein sehr schönes familiäres Altenheim\n",
            "\n",
            "   PARAPHRASEN:\n",
            "Wir sind NACH 'paras'\n",
            "   1: Ein besonders schönes familiäres Altenheim\n",
            "   2: Ein wirklich schönes familiäres Altenheim\n",
            "   3: Ein sehr schönes familiäres Altenheim\n",
            "------------------------------------------------------------------------------------------\n",
            "\n",
            "4. ORIGINAL (Index 5079):\n",
            "Verstehe manche Bewertungen nicht. Aber naja...\n",
            "\n",
            "   PARAPHRASEN:\n",
            "Wir sind NACH 'paras'\n",
            "   1: Verstehe manche Bewertungen nicht. Aber naja...\n",
            "   2: Verstehe manche Bewertungen nicht. Aber naja...\n",
            "   3: Verstehe manche Bewertungen nicht. Aber naja...\n",
            "------------------------------------------------------------------------------------------\n",
            "\n",
            "5. ORIGINAL (Index 1316):\n",
            "So eine schreckliche Heim habe ich nie im meinem Leben gesehen.\n",
            "\n",
            "   PARAPHRASEN:\n",
            "Wir sind NACH 'paras'\n",
            "   1: So eine schreckliche Heim habe ich nie bei meinem Leben gesehen.\n",
            "   2: So eine schreckliche Heim habe ich nie in meinem Leben gesehen.\n",
            "   3: So eine schreckliche Heim habe ich nie im meinem Leben gesehen.\n",
            "------------------------------------------------------------------------------------------\n",
            "\n",
            "6. ORIGINAL (Index 5487):\n",
            "Nette Pflege ...\n",
            "\n",
            "   PARAPHRASEN:\n",
            "Wir sind NACH 'paras'\n",
            "   1: Nette Pflege ...\n",
            "   2: Nette Pflege ...\n",
            "   3: Nette Pflege ...\n",
            "------------------------------------------------------------------------------------------\n",
            "\n",
            "7. ORIGINAL (Index 3081):\n",
            "Die Pflegekräfte sind sehr kompetent und hilfsbereit, Das essen allerdings ist echt gewöhnungsbedürftig;D.\n",
            "\n",
            "   PARAPHRASEN:\n",
            "Wir sind NACH 'paras'\n",
            "   1: Die Pflegekräfte sind sehr kompetent sowie hilfsbereit, Das Speisen allerdings ist echt gewöhnungsbedürftig;D.\n",
            "   2: Die Pflegekräfte sind sehr kompetent und hilfsbereit, Das Nahrung allerdings ist echt gewöhnungsbedürftig;D.\n",
            "   3: Die Pflegekräfte sind wirklich kompetent sowie hilfsbereit, Das essen allerdings bleibt echt gewöhnungsbedürftig;D.\n",
            "------------------------------------------------------------------------------------------\n",
            "\n",
            "8. ORIGINAL (Index 354):\n",
            "Nicht zu empfehlenSchlechte Umgang mit alte Demenz kranke leute\n",
            "\n",
            "   PARAPHRASEN:\n",
            "Wir sind NACH 'paras'\n",
            "   1: Nicht zu empfehlenSchlechte Umgang mit alte Demenz kranke leute\n",
            "   2: Nicht zu empfehlenSchlechte Umgang mit alte Demenz kranke leute\n",
            "   3: Nicht zu empfehlenSchlechte Umgang mit alte Demenz kranke leute\n",
            "------------------------------------------------------------------------------------------\n",
            "\n",
            "9. ORIGINAL (Index 3464):\n",
            "Die Preise für die Unterbringung sind sehr hoch.....\n",
            "\n",
            "   PARAPHRASEN:\n",
            "Wir sind NACH 'paras'\n",
            "   1: Die Preise für die Unterbringung sind wirklich hoch.....\n",
            "   2: Die Preise für die Unterbringung sind besonders hoch.....\n",
            "   3: Die Preise für die Unterbringung sind sehr hoch.....\n",
            "------------------------------------------------------------------------------------------\n",
            "\n",
            "10. ORIGINAL (Index 4212):\n",
            "Das neue Konzept des Cafés ist toll. Es gibt nun heiße Waffeln und Eis, alles was ein Café zu bieten. Die Atmosphäre ist sehr gemütlich. Ich komme gerne wieder.\n",
            "\n",
            "   PARAPHRASEN:\n",
            "Wir sind NACH 'paras'\n",
            "   1: Das neue Konzept des Cafés bleibt toll. Es gibt nun heiße Waffeln & Eis, alles was ein Café zu bieten. Die Atmosphäre bleibt sehr gemütlich. Ich komme gerne wieder.\n",
            "   2: Das neue Konzept des Cafés bleibt toll. Es gibt nun heiße Waffeln sowie Eis, alles was ein Café zu bieten. Die Atmosphäre bleibt sehr gemütlich. Ich komme gerne wieder.\n",
            "   3: Das neue Konzept des Cafés bleibt toll. Es gibt nun heiße Waffeln – Eis, alles was ein Café zu bieten. Die Atmosphäre bleibt sehr gemütlich. Ich komme gerne wieder.\n",
            "------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyC2F4CTW-2d"
      },
      "outputs": [],
      "source": [
        "# finaler Batch: Alle Rezensionen aus \"efahrungen_clean.csv\" augmentieren\n",
        "print(f\"\\nSTART: Paraphrasierung aller {len(df)} Rezensionen -> {len(df)*3} Samples...\")\n",
        "aug_data = []\n",
        "\n",
        "for idx in tqdm(range(len(df)), desc=\"Augmentiere\", unit=\"text\"):\n",
        "    text = df.iloc[idx]['Erfahrungsbericht des Nutzers']\n",
        "    variants = hybrid_paraphrase(text, 3)\n",
        "    for v_id, para in enumerate(variants, 1):\n",
        "        aug_data.append({\n",
        "            'original_index': idx,\n",
        "            'original': text,\n",
        "            'paraphrase': para,\n",
        "            'variant_id': v_id\n",
        "        })\n",
        "\n",
        "# Speichern\n",
        "aug_df = pd.DataFrame(aug_data)\n",
        "output_path = \"/content/drive/MyDrive/ABSA_Paraphrase/augmented_erfahrungen.csv\"\n",
        "aug_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"\\nFERTIG!\")\n",
        "print(f\"→ {len(aug_df)} Paraphrasen gespeichert\")\n",
        "print(f\"→ Datei: {output_path}\")\n",
        "print(f\"→ Robuster Datensatz für Grok 3 Mini bei der ABSA vorbereitet!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfZm6aOvPbPD"
      },
      "source": [
        "für Fine Tuning:\n",
        "Hugging Face: Fine-tune ein Grok-ähnliches Modell (z. B. \"xai-org/grok-1\" oder \"reedmayhew/Grok-3-gemma3-4B-distilled\" als Distillation von Grok 3). Das ist open-source und GitHub-freundlich.\n",
        "\n",
        "Code-Beispiel (Distillation von Grok 3 via API + Fine-Tuning auf Gemma-3 4B):\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0ywlg4TQWl2"
      },
      "source": [
        "Best Practices (aus Reddit, GitHub Blog, HF Docs):\n",
        "\n",
        "Lizenz: Füge eine LICENSE (z. B. Apache 2.0) hinzu, da Grok-Modelle proprietär sind – dein Fine-Tuning erbt das.\n",
        "Model Card: Erstelle eine (HF-Template: https://huggingface.co/docs/hub/model-cards) mit Details zu Daten (12.000 Rezensionen), Augmentation und Metriken.\n",
        "Datenschutz: Anonymisiere sensible Daten in der CSV (z. B. Namen entfernen), bevor du hochlädst – Pflegeberichte könnten personenbezogen sein (DSGVO-konform!).\n",
        "Versionskontrolle: Nutze GitHub Releases für große Dateien (z. B. Weights als Asset).\n",
        "Integration mit HF: Push zu Hugging Face Hub und verlinke im GitHub-Repo – HF ist GitHub-ähnlich und unterstützt Grok-Destillationen (z. B. \"reedmayhew/Grok-3-gemma3-4B-distilled\").\n",
        "\n",
        "\n",
        "\n",
        "3. Empfehlung für deine Bachelorarbeit\n",
        "\n",
        "Starte mit Option A/B: Prompt Engineering für schnelle Tests, dann Hugging Face für echtes Fine-Tuning (ca. 30–60 Min. in Colab mit GPU).\n",
        "GitHub-Repo als Portfolio: Lade Code, Skripte und Metriken hoch – das zeigt Reproduzierbarkeit. Vermeide rohe Weights (>100 MB) direkt; verlinke sie.\n",
        "Nächste Schritte: Hole dir einen xAI API-Key und HF-Token. Teste den Code in Colab.\n",
        "\n",
        "Falls du Hilfe beim Setup (z. B. API-Key, spezifischer Code-Fehler) brauchst oder mehr Details zu einer Option, lass es mich wissen!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b06VD1uYFlSq"
      },
      "outputs": [],
      "source": [
        "# um damit zu beginnen: https://arxiv.org/html/2507.09485"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1MecGjdw--8eqoUfF53VL3Vja6L0ROuUF",
      "authorship_tag": "ABX9TyM8Pv+n/khWDGFn6m2reuR5"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}